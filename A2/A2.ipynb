{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> COGS 118B Assignment 2 </u>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0 : Academic Integrity (1 point)\n",
    "\n",
    " What is allowed:\n",
    "\n",
    "1. Studying material using online resources.\n",
    "2. Consulting online resources to help with the assignments and providing citations. \n",
    "3. Collaborate with classmates (ex: studying for the exam in pairs and fixing each otherâ€™s code.)\n",
    "4. Asking ChatGPT to help you understand concepts. (make sure ChatGPT is speaking the truth) If you are studying for a concept that is in an assignment, make sure to provide citations. (ex. What prompt did you use?)\n",
    "\n",
    "What is NOT allowed:\n",
    "\n",
    "1. Copying answers from online resources word by word. If you cannot understand it, do not copy it.\n",
    "\n",
    "2. Copying answers from your peers.\n",
    "3. Using answers directly generated by ChatGPT or other AI tools. If you used AI tools to help you answer homework questions, please cite the AI tools you have used. Directly copying and pasting solutions from online tools without proper learning and citations is considered cheating. It would not be smart to cheat using machine learning tools in a machine learning class. We will flag you if we detect any suspicious responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have read the rules above, respond \"I understand I have to provide citations.\" below.\n",
    "\n",
    "(YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 \n",
    "\n",
    "In this part of the assignment we will be applying PCA and **K-means clustering** on multi-dimensional data points. We will then implement the **EM** algorithm on the same dataset (with the assist of PCA) and we can visualize the performance of the two algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The dataset:\n",
    "We are using real student data recorded from Cogs. Sci. students. We have removed sensitive information such as student PID and names. You can look at the column names to see the range and the type of numbers we are handling. Applying a clustering algorithm to the dataset allows us to find hidden student groups. Once we have defined distinct student groups, we can further analyze the data and look into a personalized method of teaching to better assist with students' learning. Hence, clustering is a helpful technique when doing research in pedagogy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('PA2_data.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA, we have to transform the dataframe into a Numpy matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.to_numpy()\n",
    "\n",
    "X = X[:,1:].astype(float)\n",
    "X = X/X.max(axis=0)           # scaling the values to [0,1] range. We can divided by the max value of each column because we do not have negative values in the data.\n",
    "print('Shape of X: ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-do** (1.1): (2 points)\n",
    "\n",
    "Apply PCA on the dataset `X` using the PCA package from sklearn. Set the number of principle components to 2. No need to normalize the data since it has already been processed for you. \n",
    "\n",
    "Plot the transformed data onto a 2-d scatter plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_pca = ... # Your code here\n",
    "plt.scatter(...) # Your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-do** (1.2) (2 point) \n",
    "\n",
    "Use KM clustering module from SkLearn to perform clustering on the PCA transformed dataset. Set the number of clusters (k) = 4. (Notice that since clusters are not circular blobs, K-mean cannot cluster in an interpretable way.)\n",
    "\n",
    "Plot the colored clusters. (Like we did in the first assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n",
    "labels = ...\n",
    "plt.scatter(...)# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - EM\n",
    "\n",
    "EM Algorithm finds clusters by treating each cluster as a 2D Gaussian distribution, and then fits the parameters of each distribution to accurately model the data. The goal is to find the optimal parameters for each of the Gaussians which model the data accurately.\n",
    "\n",
    "Each cluster distribution is of the form $\\pi_c \\mathcal{N}(\\mu_c, \\sum_c)$, for each cluster $c, 0 \\leq c < k$. For each cluster, we have the parameters $\\mu_c, \\pi_c$ and $\\sum_c$.\n",
    "\n",
    "$\\pi_c$ denotes the cluster \"strength\" or \"size\" for each cluster. It represents the prior strength for a cluster, i.e. how likely it is that any point in the dataset belongs to that cluster.\n",
    "\n",
    "$\\mu_c$ denotes the cluster mean (a 2D point). The cluster distribution is centered around this point.\n",
    "\n",
    "$\\sum_c$ denotes the cluster covariance. Covariance is a generalization of variance $\\sigma$ to multiple variables (in our case, 2D coordinates). It is a $2 \\times 2$ matrix which represents the spread of each of the $x$ and $y$ coordinates.\n",
    "\n",
    "The EM Algorithm has 2 steps, which are repeated till convergence:\n",
    "- Expectation: We treat all of the cluster parameters as fixed. We then compute the probabilities of each point belonging to each cluster.\n",
    "- Maximization: We treat the cluster probabilities as fixed and update the distribution parameters.\n",
    "\n",
    "We start by initializing our EMModel class. This is the main class which will store our data and distribution parameters. We will also write all the functionality in it.\n",
    "\n",
    "`X` is a matrix of size $N \\times 2$\n",
    "\n",
    "`k` is the number of clusters we want (4 in our case).\n",
    "\n",
    "`max_iters` is the number of iterations we will run the algorithm for.\n",
    "\n",
    "`self.dim` is the number of dimensions (2 in our case).\n",
    "\n",
    "`self.N` is the number of points in the dataset (500 in our case).\n",
    "\n",
    "`self.mu` stores all the cluster means. Size is $k \\times 2$, as we have to store one point for each cluster.We initialize the cluster means by randomly picking k points from the dataset. \n",
    "\n",
    "`self.pi` stores all the cluster priors (strengths). Size is $k \\times 1$, as it is just one number for each cluster. It is initialized to $\\frac{1}{k}$ for each cluster.\n",
    "\n",
    "`self.sigma` stores all the cluster covariance matrices. Size is $k \\times 2 \\times 2$, as we have to store a $2 \\times 2$ matrix for each cluster. It is initialized to diagonal matrices with diagonal value $5.0$.\n",
    "\n",
    "### Useful functions\n",
    "\n",
    "To draw values from a multivariate normal distribution, use the `scipy.stats.multivariate_normal` function. For example, to draw values from a normal distribution with mean `mu` and covariance matrix `sigma`, you can use the following code:\n",
    "\n",
    "`val = multivariate_normal(mean=mu, cov=sigma).pdf(X)` where `X` is an $N \\times 2$ matrix.\n",
    "\n",
    "**To-do:** (2.1)  (2 points)\n",
    "\n",
    "Initialize `self.mu` , `self.pi`, and `self.sigma` according to the descriptions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMModel:\n",
    "    \n",
    "    def __init__(self, X, k, max_iters):\n",
    "        \"\"\"\n",
    "        This function initializes our parameters (mu, pi and sigma) and plots our data points.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.k = k\n",
    "        self.max_iters = max_iters\n",
    "        \n",
    "        self.dim = self.X.shape[1] # Equals 2, as we are considering 2D points\n",
    "        self.N = self.X.shape[0] # Equals the number of points in the dataset\n",
    "        \n",
    "        \"\"\"\n",
    "        Here we initialize mu, pi and sigma. Mu is k X 2, Pi is k X 1, Sigma is k X 2 X 2\n",
    "        \"\"\"\n",
    "        self.mu = ...  #YOUR CODE HERE\n",
    "        self.pi =  ... # YOUR CODE HERE\n",
    "        self.sigma = ... # YOUR CODE HERE\n",
    "            \n",
    "        \"\"\"\n",
    "        This part is required to plot clusters\n",
    "        \"\"\"\n",
    "        x,y = np.meshgrid(np.sort(self.X[:,0]),np.sort(self.X[:,1]))\n",
    "        self.XY = np.array([x.flatten(),y.flatten()]).T\n",
    "            \n",
    "        \"\"\"\n",
    "        Finally, let's visualize our data points\n",
    "        \"\"\"\n",
    "        self.plot_data('Initial State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function `plot_data` to plot our data as well as our clusters. This function plots our data points, and creates a contour plot for each cluster using its `mu` and `sigma` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def plot_data(self, title, colors=None):\n",
    "    \"\"\"\n",
    "    This function creates a scatter plot of all the data points. It also creates a contour plot of the probability \n",
    "    distributions of each of the clusters (specified by mu, pi and sigma)\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax0 = fig.add_subplot(111)\n",
    "    ax0.scatter(self.X[:,0], self.X[:,1], c=colors)\n",
    "    ax0.set_title(title)\n",
    "    for m,c in zip(self.mu,self.sigma):\n",
    "        multi_normal = multivariate_normal(mean=m,cov=c)\n",
    "        ax0.contour(np.sort(self.X[:,0]),np.sort(self.X[:,1]),multi_normal.pdf(self.XY).reshape(len(self.X),len(self.X)),colors='black',alpha=0.3)\n",
    "        ax0.scatter(m[0],m[1],c='grey',zorder=10,s=100)\n",
    "        \n",
    "EMModel.plot_data = plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our `expectation` function. This function's job is to compute $r_{ic}$, which is the probability that point $i$ belongs to cluster $c$ . ($0 \\leq i < N$, $0 \\leq c < k$)\n",
    "\n",
    "We will store $r_{ic}$ as a matrix of size $N \\times k$. (as we have to store the probability of every point for each cluster).\n",
    "\n",
    "$r_{ic}$ is computed as follows:\n",
    "<img src=\"ric.png\">\n",
    "\n",
    "To compute it, we basically:\n",
    "- compute its probability under cluster model $c$\n",
    "- normalize it to sum to 1 using its probabilities from all the clusters\n",
    "\n",
    "Finally we should return `r` after computing it.\n",
    "\n",
    "**To-do:** (2.2)  (10 points)\n",
    "\n",
    "Complete the `expectation` method. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation(self):\n",
    "    # YOUR CODE HERE\n",
    "    r = ...\n",
    "    return r\n",
    "    \n",
    "EMModel.expectation = expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the \"maximization\" step in the `maximization` function. This function's job is to take the previously computed $r_{ic}$ and update the parameters $\\mu_c, \\sum_c$ of each cluster distribution. This is done as follows:\n",
    "<img src=\"m2.png\">\n",
    "\n",
    "\n",
    "### Here, $N = \\sum_{c} N_c$\n",
    "\n",
    "Basically you should re-compute `mu`, `sigma` and `pi` using the previously computed `r` as per the given formulas.\n",
    "\n",
    "**To-do:** (5 points)\n",
    "\n",
    "\n",
    "Complete the `maximization` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximization(self, r):\n",
    "    # YOUR CODE HERE\n",
    "    ...\n",
    "    \n",
    "EMModel.maximization = maximization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write our main `run()` function which runs the EM Algorithm. This performs `max_iter` iterations of expectation and maximization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-do:** (2.3)   (3 points)\n",
    "\n",
    "Complete the `run` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(self):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    ...\n",
    "\n",
    "    color_labels = ... # YOUR CODE HERE\n",
    "    self.plot_data('Final State', color_labels)\n",
    "    \n",
    "EMModel.run = run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we instantiate the `EMModel` class and run the algorithm on the PCA transformed 2 dimensional class data.\n",
    "\n",
    "**To-do:** (2.4)  (1 point)\n",
    "\n",
    "Run EM on the dataset. Your labeled cluster plot should look a lot better than the one from K-means. \n",
    "\n",
    "Use any parameters you think they are appropriate for our dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Hierarchical Clustering\n",
    "\n",
    "Hierarchical Clustering is another useful clustering algorithm. One unique feature of the hierarchical clustering is that it is able to generate within-cluster clusters. A super cluster can have multiple subclusters. Finding the subclusters can help us understand additional distributions on dataset with multiple features.\n",
    "\n",
    "**To-do:**(3.1)  (2 points)\n",
    "\n",
    "1. Use the hierarchy module from scipy (`scipy.cluser.hierarchy`) to produce a linkage matrix of the PCA transformed class dataset. \n",
    "Read the documentation on the linkage method. Make sure to choose a distance method that would produce a meaningful dendrogram.\n",
    "\n",
    "Documentaton on the linkage method: https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html\n",
    "\n",
    "2. Plot the dendrogram using the `dendrogram` method. \n",
    "Documentation on the dendrogram method: https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOP ! Have you run all the code blocks ? \n",
    "If not, please do so. All the requested code output should be visible. \n",
    "\n",
    "## Submission:\n",
    "Please submit your notebook (.ipynb file) and an exported PDF copy (you can upload seperately without zipping the files) on GradeScope under the correct assignment with all of the cell outputs visible. It is normal to see Grapescope auto-grader outputs a score of 0.\n",
    "\n",
    "If you are running on Datahub or the Anaconda Navigator and you are having trouble with exporting to PDF, you can use browser print page. If nothing works, you can submit without the PDF. Note, the .ipynb notebook file is required. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "77eee26a74623a023872d1bc89eff3417ddfa96c1608d48d76f7b381bf2c2567"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
